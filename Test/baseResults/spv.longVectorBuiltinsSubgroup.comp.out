spv.longVectorBuiltinsSubgroup.comp
// Module Version 10300
// Generated by (magic number): 8000b
// Id's are bound by 636

                              Capability Shader
                              Capability Float64
                              Capability Int64
                              Capability GroupNonUniform
                              Capability GroupNonUniformVote
                              Capability GroupNonUniformArithmetic
                              Capability GroupNonUniformBallot
                              Capability GroupNonUniformShuffle
                              Capability GroupNonUniformShuffleRelative
                              Capability GroupNonUniformClustered
                              Capability GroupNonUniformQuad
                              Capability GroupNonUniformPartitionedNV
                              Capability LongVectorEXT
                              Capability GroupNonUniformRotateKHR
                              Extension  "SPV_EXT_long_vector"
                              Extension  "SPV_KHR_subgroup_rotate"
                              Extension  "SPV_NV_shader_subgroup_partitioned"
               1:             ExtInstImport  "GLSL.std.450"
                              MemoryModel Logical GLSL450
                              EntryPoint GLCompute 4  "main"
                              ExecutionMode 4 LocalSize 64 1 1
                              Source GLSL 450
                              SourceExtension  "GL_EXT_bfloat16"
                              SourceExtension  "GL_EXT_buffer_reference"
                              SourceExtension  "GL_EXT_expect_assume"
                              SourceExtension  "GL_EXT_long_vector"
                              SourceExtension  "GL_EXT_shader_explicit_arithmetic_types"
                              SourceExtension  "GL_EXT_shader_explicit_arithmetic_types_int64"
                              SourceExtension  "GL_EXT_shader_subgroup_extended_types_int64"
                              SourceExtension  "GL_KHR_memory_scope_semantics"
                              SourceExtension  "GL_KHR_shader_subgroup_arithmetic"
                              SourceExtension  "GL_KHR_shader_subgroup_ballot"
                              SourceExtension  "GL_KHR_shader_subgroup_basic"
                              SourceExtension  "GL_KHR_shader_subgroup_clustered"
                              SourceExtension  "GL_KHR_shader_subgroup_quad"
                              SourceExtension  "GL_KHR_shader_subgroup_rotate"
                              SourceExtension  "GL_KHR_shader_subgroup_shuffle"
                              SourceExtension  "GL_KHR_shader_subgroup_shuffle_relative"
                              SourceExtension  "GL_KHR_shader_subgroup_vote"
                              SourceExtension  "GL_NV_shader_subgroup_partitioned"
                              Name 4  "main"
                              Name 8  "b"
                              Name 12  "vu32"
                              Name 23  "u"
                              Name 110  "vu4"
                              Name 179  "vf32"
                              Name 285  "vf64"
                              Name 390  "vb"
                              Name 479  "vu64"
                              Decorate 635 BuiltIn WorkgroupSize
               2:             TypeVoid
               3:             TypeFunction 2
               6:             TypeBool
               7:             TypePointer Function 6(bool)
               9:             TypeInt 32 0
              10:             TypeVector 9(int) 5
              11:             TypePointer Function 10(ivec)
              14:      9(int) Constant 3
              17:      9(int) Constant 1
              22:             TypePointer Function 9(int)
              40:      9(int) Constant 4
             101:      9(int) Constant 0
             106:      9(int) Constant 2
             108:             TypeVector 9(int) 4
             109:             TypePointer Function 108(ivec4)
             176:             TypeFloat 32
             177:             TypeVector 176(float) 5
             178:             TypePointer Function 177(fvec)
             282:             TypeFloat 64
             283:             TypeVector 282(float64_t) 5
             284:             TypePointer Function 283(f64vec)
             388:             TypeVector 6(bool) 5
             389:             TypePointer Function 388(bvec)
             476:             TypeInt 64 0
             477:             TypeVector 476(int64_t) 5
             478:             TypePointer Function 477(i64vec)
             633:             TypeVector 9(int) 3
             634:      9(int) Constant 64
             635:  633(ivec3) ConstantComposite 634 17 17
         4(main):           2 Function None 3
               5:             Label
            8(b):      7(ptr) Variable Function
        12(vu32):     11(ptr) Variable Function
           23(u):     22(ptr) Variable Function
        110(vu4):    109(ptr) Variable Function
       179(vf32):    178(ptr) Variable Function
       285(vf64):    284(ptr) Variable Function
         390(vb):    389(ptr) Variable Function
       479(vu64):    478(ptr) Variable Function
              13:    10(ivec) Load 12(vu32)
              15:     6(bool) GroupNonUniformAllEqual 14 13
                              Store 8(b) 15
              16:    10(ivec) Load 12(vu32)
              18:    10(ivec) GroupNonUniformBroadcast 14 16 17
                              Store 12(vu32) 18
              19:    10(ivec) Load 12(vu32)
              20:    10(ivec) GroupNonUniformBroadcastFirst 14 19
                              Store 12(vu32) 20
              21:    10(ivec) Load 12(vu32)
              24:      9(int) Load 23(u)
              25:    10(ivec) GroupNonUniformShuffle 14 21 24
                              Store 12(vu32) 25
              26:    10(ivec) Load 12(vu32)
              27:      9(int) Load 23(u)
              28:    10(ivec) GroupNonUniformShuffleXor 14 26 27
                              Store 12(vu32) 28
              29:    10(ivec) Load 12(vu32)
              30:      9(int) Load 23(u)
              31:    10(ivec) GroupNonUniformShuffleUp 14 29 30
                              Store 12(vu32) 31
              32:    10(ivec) Load 12(vu32)
              33:      9(int) Load 23(u)
              34:    10(ivec) GroupNonUniformShuffleDown 14 32 33
                              Store 12(vu32) 34
              35:    10(ivec) Load 12(vu32)
              36:      9(int) Load 23(u)
              37:    10(ivec) GroupNonUniformRotateKHR 14 35 36
                              Store 12(vu32) 37
              38:    10(ivec) Load 12(vu32)
              39:      9(int) Load 23(u)
              41:    10(ivec) GroupNonUniformRotateKHR 14 38 39 40
                              Store 12(vu32) 41
              42:    10(ivec) Load 12(vu32)
              43:    10(ivec) GroupNonUniformIAdd 14 Reduce 42
                              Store 12(vu32) 43
              44:    10(ivec) Load 12(vu32)
              45:    10(ivec) GroupNonUniformIMul 14 Reduce 44
                              Store 12(vu32) 45
              46:    10(ivec) Load 12(vu32)
              47:    10(ivec) GroupNonUniformUMin 14 Reduce 46
                              Store 12(vu32) 47
              48:    10(ivec) Load 12(vu32)
              49:    10(ivec) GroupNonUniformUMax 14 Reduce 48
                              Store 12(vu32) 49
              50:    10(ivec) Load 12(vu32)
              51:    10(ivec) GroupNonUniformBitwiseAnd 14 Reduce 50
                              Store 12(vu32) 51
              52:    10(ivec) Load 12(vu32)
              53:    10(ivec) GroupNonUniformBitwiseOr 14 Reduce 52
                              Store 12(vu32) 53
              54:    10(ivec) Load 12(vu32)
              55:    10(ivec) GroupNonUniformBitwiseXor 14 Reduce 54
                              Store 12(vu32) 55
              56:    10(ivec) Load 12(vu32)
              57:    10(ivec) GroupNonUniformIAdd 14 InclusiveScan 56
                              Store 12(vu32) 57
              58:    10(ivec) Load 12(vu32)
              59:    10(ivec) GroupNonUniformIMul 14 InclusiveScan 58
                              Store 12(vu32) 59
              60:    10(ivec) Load 12(vu32)
              61:    10(ivec) GroupNonUniformUMin 14 InclusiveScan 60
                              Store 12(vu32) 61
              62:    10(ivec) Load 12(vu32)
              63:    10(ivec) GroupNonUniformUMax 14 InclusiveScan 62
                              Store 12(vu32) 63
              64:    10(ivec) Load 12(vu32)
              65:    10(ivec) GroupNonUniformBitwiseAnd 14 InclusiveScan 64
                              Store 12(vu32) 65
              66:    10(ivec) Load 12(vu32)
              67:    10(ivec) GroupNonUniformBitwiseOr 14 InclusiveScan 66
                              Store 12(vu32) 67
              68:    10(ivec) Load 12(vu32)
              69:    10(ivec) GroupNonUniformBitwiseXor 14 InclusiveScan 68
                              Store 12(vu32) 69
              70:    10(ivec) Load 12(vu32)
              71:    10(ivec) GroupNonUniformIAdd 14 ExclusiveScan 70
                              Store 12(vu32) 71
              72:    10(ivec) Load 12(vu32)
              73:    10(ivec) GroupNonUniformIMul 14 ExclusiveScan 72
                              Store 12(vu32) 73
              74:    10(ivec) Load 12(vu32)
              75:    10(ivec) GroupNonUniformUMin 14 ExclusiveScan 74
                              Store 12(vu32) 75
              76:    10(ivec) Load 12(vu32)
              77:    10(ivec) GroupNonUniformUMax 14 ExclusiveScan 76
                              Store 12(vu32) 77
              78:    10(ivec) Load 12(vu32)
              79:    10(ivec) GroupNonUniformBitwiseAnd 14 ExclusiveScan 78
                              Store 12(vu32) 79
              80:    10(ivec) Load 12(vu32)
              81:    10(ivec) GroupNonUniformBitwiseOr 14 ExclusiveScan 80
                              Store 12(vu32) 81
              82:    10(ivec) Load 12(vu32)
              83:    10(ivec) GroupNonUniformBitwiseXor 14 ExclusiveScan 82
                              Store 12(vu32) 83
              84:    10(ivec) Load 12(vu32)
              85:    10(ivec) GroupNonUniformIAdd 14 ClusteredReduce 84 40
                              Store 12(vu32) 85
              86:    10(ivec) Load 12(vu32)
              87:    10(ivec) GroupNonUniformIMul 14 ClusteredReduce 86 40
                              Store 12(vu32) 87
              88:    10(ivec) Load 12(vu32)
              89:    10(ivec) GroupNonUniformUMin 14 ClusteredReduce 88 40
                              Store 12(vu32) 89
              90:    10(ivec) Load 12(vu32)
              91:    10(ivec) GroupNonUniformUMax 14 ClusteredReduce 90 40
                              Store 12(vu32) 91
              92:    10(ivec) Load 12(vu32)
              93:    10(ivec) GroupNonUniformBitwiseAnd 14 ClusteredReduce 92 40
                              Store 12(vu32) 93
              94:    10(ivec) Load 12(vu32)
              95:    10(ivec) GroupNonUniformBitwiseOr 14 ClusteredReduce 94 40
                              Store 12(vu32) 95
              96:    10(ivec) Load 12(vu32)
              97:    10(ivec) GroupNonUniformBitwiseXor 14 ClusteredReduce 96 40
                              Store 12(vu32) 97
              98:    10(ivec) Load 12(vu32)
              99:    10(ivec) GroupNonUniformQuadBroadcast 14 98 17
                              Store 12(vu32) 99
             100:    10(ivec) Load 12(vu32)
             102:    10(ivec) GroupNonUniformQuadSwap 14 100 101
                              Store 12(vu32) 102
             103:    10(ivec) Load 12(vu32)
             104:    10(ivec) GroupNonUniformQuadSwap 14 103 17
                              Store 12(vu32) 104
             105:    10(ivec) Load 12(vu32)
             107:    10(ivec) GroupNonUniformQuadSwap 14 105 106
                              Store 12(vu32) 107
             111:    10(ivec) Load 12(vu32)
             112:  108(ivec4) GroupNonUniformPartitionNV 111
                              Store 110(vu4) 112
             113:    10(ivec) Load 12(vu32)
             114:  108(ivec4) Load 110(vu4)
             115:    10(ivec) GroupNonUniformIAdd 14 PartitionedReduceNV 113 114
                              Store 12(vu32) 115
             116:    10(ivec) Load 12(vu32)
             117:  108(ivec4) Load 110(vu4)
             118:    10(ivec) GroupNonUniformIMul 14 PartitionedReduceNV 116 117
                              Store 12(vu32) 118
             119:    10(ivec) Load 12(vu32)
             120:  108(ivec4) Load 110(vu4)
             121:    10(ivec) GroupNonUniformUMin 14 PartitionedReduceNV 119 120
                              Store 12(vu32) 121
             122:    10(ivec) Load 12(vu32)
             123:  108(ivec4) Load 110(vu4)
             124:    10(ivec) GroupNonUniformUMax 14 PartitionedReduceNV 122 123
                              Store 12(vu32) 124
             125:    10(ivec) Load 12(vu32)
             126:  108(ivec4) Load 110(vu4)
             127:    10(ivec) GroupNonUniformBitwiseAnd 14 PartitionedReduceNV 125 126
                              Store 12(vu32) 127
             128:    10(ivec) Load 12(vu32)
             129:  108(ivec4) Load 110(vu4)
             130:    10(ivec) GroupNonUniformBitwiseOr 14 PartitionedReduceNV 128 129
                              Store 12(vu32) 130
             131:    10(ivec) Load 12(vu32)
             132:  108(ivec4) Load 110(vu4)
             133:    10(ivec) GroupNonUniformBitwiseXor 14 PartitionedReduceNV 131 132
                              Store 12(vu32) 133
             134:    10(ivec) Load 12(vu32)
             135:  108(ivec4) Load 110(vu4)
             136:    10(ivec) GroupNonUniformIAdd 14 PartitionedInclusiveScanNV 134 135
                              Store 12(vu32) 136
             137:    10(ivec) Load 12(vu32)
             138:  108(ivec4) Load 110(vu4)
             139:    10(ivec) GroupNonUniformIMul 14 PartitionedInclusiveScanNV 137 138
                              Store 12(vu32) 139
             140:    10(ivec) Load 12(vu32)
             141:  108(ivec4) Load 110(vu4)
             142:    10(ivec) GroupNonUniformUMin 14 PartitionedInclusiveScanNV 140 141
                              Store 12(vu32) 142
             143:    10(ivec) Load 12(vu32)
             144:  108(ivec4) Load 110(vu4)
             145:    10(ivec) GroupNonUniformUMax 14 PartitionedInclusiveScanNV 143 144
                              Store 12(vu32) 145
             146:    10(ivec) Load 12(vu32)
             147:  108(ivec4) Load 110(vu4)
             148:    10(ivec) GroupNonUniformBitwiseAnd 14 PartitionedInclusiveScanNV 146 147
                              Store 12(vu32) 148
             149:    10(ivec) Load 12(vu32)
             150:  108(ivec4) Load 110(vu4)
             151:    10(ivec) GroupNonUniformBitwiseOr 14 PartitionedInclusiveScanNV 149 150
                              Store 12(vu32) 151
             152:    10(ivec) Load 12(vu32)
             153:  108(ivec4) Load 110(vu4)
             154:    10(ivec) GroupNonUniformBitwiseXor 14 PartitionedInclusiveScanNV 152 153
                              Store 12(vu32) 154
             155:    10(ivec) Load 12(vu32)
             156:  108(ivec4) Load 110(vu4)
             157:    10(ivec) GroupNonUniformIAdd 14 PartitionedExclusiveScanNV 155 156
                              Store 12(vu32) 157
             158:    10(ivec) Load 12(vu32)
             159:  108(ivec4) Load 110(vu4)
             160:    10(ivec) GroupNonUniformIMul 14 PartitionedExclusiveScanNV 158 159
                              Store 12(vu32) 160
             161:    10(ivec) Load 12(vu32)
             162:  108(ivec4) Load 110(vu4)
             163:    10(ivec) GroupNonUniformUMin 14 PartitionedExclusiveScanNV 161 162
                              Store 12(vu32) 163
             164:    10(ivec) Load 12(vu32)
             165:  108(ivec4) Load 110(vu4)
             166:    10(ivec) GroupNonUniformUMax 14 PartitionedExclusiveScanNV 164 165
                              Store 12(vu32) 166
             167:    10(ivec) Load 12(vu32)
             168:  108(ivec4) Load 110(vu4)
             169:    10(ivec) GroupNonUniformBitwiseAnd 14 PartitionedExclusiveScanNV 167 168
                              Store 12(vu32) 169
             170:    10(ivec) Load 12(vu32)
             171:  108(ivec4) Load 110(vu4)
             172:    10(ivec) GroupNonUniformBitwiseOr 14 PartitionedExclusiveScanNV 170 171
                              Store 12(vu32) 172
             173:    10(ivec) Load 12(vu32)
             174:  108(ivec4) Load 110(vu4)
             175:    10(ivec) GroupNonUniformBitwiseXor 14 PartitionedExclusiveScanNV 173 174
                              Store 12(vu32) 175
             180:   177(fvec) Load 179(vf32)
             181:     6(bool) GroupNonUniformAllEqual 14 180
                              Store 8(b) 181
             182:   177(fvec) Load 179(vf32)
             183:   177(fvec) GroupNonUniformBroadcast 14 182 17
                              Store 179(vf32) 183
             184:   177(fvec) Load 179(vf32)
             185:   177(fvec) GroupNonUniformBroadcastFirst 14 184
                              Store 179(vf32) 185
             186:   177(fvec) Load 179(vf32)
             187:      9(int) Load 23(u)
             188:   177(fvec) GroupNonUniformShuffle 14 186 187
                              Store 179(vf32) 188
             189:   177(fvec) Load 179(vf32)
             190:      9(int) Load 23(u)
             191:   177(fvec) GroupNonUniformShuffleXor 14 189 190
                              Store 179(vf32) 191
             192:   177(fvec) Load 179(vf32)
             193:      9(int) Load 23(u)
             194:   177(fvec) GroupNonUniformShuffleUp 14 192 193
                              Store 179(vf32) 194
             195:   177(fvec) Load 179(vf32)
             196:      9(int) Load 23(u)
             197:   177(fvec) GroupNonUniformShuffleDown 14 195 196
                              Store 179(vf32) 197
             198:   177(fvec) Load 179(vf32)
             199:      9(int) Load 23(u)
             200:   177(fvec) GroupNonUniformRotateKHR 14 198 199
                              Store 179(vf32) 200
             201:   177(fvec) Load 179(vf32)
             202:      9(int) Load 23(u)
             203:   177(fvec) GroupNonUniformRotateKHR 14 201 202 40
                              Store 179(vf32) 203
             204:   177(fvec) Load 179(vf32)
             205:   177(fvec) GroupNonUniformFAdd 14 Reduce 204
                              Store 179(vf32) 205
             206:   177(fvec) Load 179(vf32)
             207:   177(fvec) GroupNonUniformFMul 14 Reduce 206
                              Store 179(vf32) 207
             208:   177(fvec) Load 179(vf32)
             209:   177(fvec) GroupNonUniformFMin 14 Reduce 208
                              Store 179(vf32) 209
             210:   177(fvec) Load 179(vf32)
             211:   177(fvec) GroupNonUniformFMax 14 Reduce 210
                              Store 179(vf32) 211
             212:   177(fvec) Load 179(vf32)
             213:   177(fvec) GroupNonUniformFAdd 14 InclusiveScan 212
                              Store 179(vf32) 213
             214:   177(fvec) Load 179(vf32)
             215:   177(fvec) GroupNonUniformFMul 14 InclusiveScan 214
                              Store 179(vf32) 215
             216:   177(fvec) Load 179(vf32)
             217:   177(fvec) GroupNonUniformFMin 14 InclusiveScan 216
                              Store 179(vf32) 217
             218:   177(fvec) Load 179(vf32)
             219:   177(fvec) GroupNonUniformFMax 14 InclusiveScan 218
                              Store 179(vf32) 219
             220:   177(fvec) Load 179(vf32)
             221:   177(fvec) GroupNonUniformFAdd 14 ExclusiveScan 220
                              Store 179(vf32) 221
             222:   177(fvec) Load 179(vf32)
             223:   177(fvec) GroupNonUniformFMul 14 ExclusiveScan 222
                              Store 179(vf32) 223
             224:   177(fvec) Load 179(vf32)
             225:   177(fvec) GroupNonUniformFMin 14 ExclusiveScan 224
                              Store 179(vf32) 225
             226:   177(fvec) Load 179(vf32)
             227:   177(fvec) GroupNonUniformFMax 14 ExclusiveScan 226
                              Store 179(vf32) 227
             228:   177(fvec) Load 179(vf32)
             229:   177(fvec) GroupNonUniformFAdd 14 ClusteredReduce 228 40
                              Store 179(vf32) 229
             230:   177(fvec) Load 179(vf32)
             231:   177(fvec) GroupNonUniformFMul 14 ClusteredReduce 230 40
                              Store 179(vf32) 231
             232:   177(fvec) Load 179(vf32)
             233:   177(fvec) GroupNonUniformFMin 14 ClusteredReduce 232 40
                              Store 179(vf32) 233
             234:   177(fvec) Load 179(vf32)
             235:   177(fvec) GroupNonUniformFMax 14 ClusteredReduce 234 40
                              Store 179(vf32) 235
             236:   177(fvec) Load 179(vf32)
             237:   177(fvec) GroupNonUniformQuadBroadcast 14 236 17
                              Store 179(vf32) 237
             238:   177(fvec) Load 179(vf32)
             239:   177(fvec) GroupNonUniformQuadSwap 14 238 101
                              Store 179(vf32) 239
             240:   177(fvec) Load 179(vf32)
             241:   177(fvec) GroupNonUniformQuadSwap 14 240 17
                              Store 179(vf32) 241
             242:   177(fvec) Load 179(vf32)
             243:   177(fvec) GroupNonUniformQuadSwap 14 242 106
                              Store 179(vf32) 243
             244:   177(fvec) Load 179(vf32)
             245:  108(ivec4) GroupNonUniformPartitionNV 244
                              Store 110(vu4) 245
             246:   177(fvec) Load 179(vf32)
             247:  108(ivec4) Load 110(vu4)
             248:   177(fvec) GroupNonUniformFAdd 14 PartitionedReduceNV 246 247
                              Store 179(vf32) 248
             249:   177(fvec) Load 179(vf32)
             250:  108(ivec4) Load 110(vu4)
             251:   177(fvec) GroupNonUniformFMul 14 PartitionedReduceNV 249 250
                              Store 179(vf32) 251
             252:   177(fvec) Load 179(vf32)
             253:  108(ivec4) Load 110(vu4)
             254:   177(fvec) GroupNonUniformFMin 14 PartitionedReduceNV 252 253
                              Store 179(vf32) 254
             255:   177(fvec) Load 179(vf32)
             256:  108(ivec4) Load 110(vu4)
             257:   177(fvec) GroupNonUniformFMax 14 PartitionedReduceNV 255 256
                              Store 179(vf32) 257
             258:   177(fvec) Load 179(vf32)
             259:  108(ivec4) Load 110(vu4)
             260:   177(fvec) GroupNonUniformFAdd 14 PartitionedInclusiveScanNV 258 259
                              Store 179(vf32) 260
             261:   177(fvec) Load 179(vf32)
             262:  108(ivec4) Load 110(vu4)
             263:   177(fvec) GroupNonUniformFMul 14 PartitionedInclusiveScanNV 261 262
                              Store 179(vf32) 263
             264:   177(fvec) Load 179(vf32)
             265:  108(ivec4) Load 110(vu4)
             266:   177(fvec) GroupNonUniformFMin 14 PartitionedInclusiveScanNV 264 265
                              Store 179(vf32) 266
             267:   177(fvec) Load 179(vf32)
             268:  108(ivec4) Load 110(vu4)
             269:   177(fvec) GroupNonUniformFMax 14 PartitionedInclusiveScanNV 267 268
                              Store 179(vf32) 269
             270:   177(fvec) Load 179(vf32)
             271:  108(ivec4) Load 110(vu4)
             272:   177(fvec) GroupNonUniformFAdd 14 PartitionedExclusiveScanNV 270 271
                              Store 179(vf32) 272
             273:   177(fvec) Load 179(vf32)
             274:  108(ivec4) Load 110(vu4)
             275:   177(fvec) GroupNonUniformFMul 14 PartitionedExclusiveScanNV 273 274
                              Store 179(vf32) 275
             276:   177(fvec) Load 179(vf32)
             277:  108(ivec4) Load 110(vu4)
             278:   177(fvec) GroupNonUniformFMin 14 PartitionedExclusiveScanNV 276 277
                              Store 179(vf32) 278
             279:   177(fvec) Load 179(vf32)
             280:  108(ivec4) Load 110(vu4)
             281:   177(fvec) GroupNonUniformFMax 14 PartitionedExclusiveScanNV 279 280
                              Store 179(vf32) 281
             286: 283(f64vec) Load 285(vf64)
             287:     6(bool) GroupNonUniformAllEqual 14 286
                              Store 8(b) 287
             288: 283(f64vec) Load 285(vf64)
             289: 283(f64vec) GroupNonUniformBroadcast 14 288 17
                              Store 285(vf64) 289
             290: 283(f64vec) Load 285(vf64)
             291: 283(f64vec) GroupNonUniformBroadcastFirst 14 290
                              Store 285(vf64) 291
             292: 283(f64vec) Load 285(vf64)
             293:      9(int) Load 23(u)
             294: 283(f64vec) GroupNonUniformShuffle 14 292 293
                              Store 285(vf64) 294
             295: 283(f64vec) Load 285(vf64)
             296:      9(int) Load 23(u)
             297: 283(f64vec) GroupNonUniformShuffleXor 14 295 296
                              Store 285(vf64) 297
             298: 283(f64vec) Load 285(vf64)
             299:      9(int) Load 23(u)
             300: 283(f64vec) GroupNonUniformShuffleUp 14 298 299
                              Store 285(vf64) 300
             301: 283(f64vec) Load 285(vf64)
             302:      9(int) Load 23(u)
             303: 283(f64vec) GroupNonUniformShuffleDown 14 301 302
                              Store 285(vf64) 303
             304: 283(f64vec) Load 285(vf64)
             305:      9(int) Load 23(u)
             306: 283(f64vec) GroupNonUniformRotateKHR 14 304 305
                              Store 285(vf64) 306
             307: 283(f64vec) Load 285(vf64)
             308:      9(int) Load 23(u)
             309: 283(f64vec) GroupNonUniformRotateKHR 14 307 308 40
                              Store 285(vf64) 309
             310: 283(f64vec) Load 285(vf64)
             311: 283(f64vec) GroupNonUniformFAdd 14 Reduce 310
                              Store 285(vf64) 311
             312: 283(f64vec) Load 285(vf64)
             313: 283(f64vec) GroupNonUniformFMul 14 Reduce 312
                              Store 285(vf64) 313
             314: 283(f64vec) Load 285(vf64)
             315: 283(f64vec) GroupNonUniformFMin 14 Reduce 314
                              Store 285(vf64) 315
             316: 283(f64vec) Load 285(vf64)
             317: 283(f64vec) GroupNonUniformFMax 14 Reduce 316
                              Store 285(vf64) 317
             318: 283(f64vec) Load 285(vf64)
             319: 283(f64vec) GroupNonUniformFAdd 14 InclusiveScan 318
                              Store 285(vf64) 319
             320: 283(f64vec) Load 285(vf64)
             321: 283(f64vec) GroupNonUniformFMul 14 InclusiveScan 320
                              Store 285(vf64) 321
             322: 283(f64vec) Load 285(vf64)
             323: 283(f64vec) GroupNonUniformFMin 14 InclusiveScan 322
                              Store 285(vf64) 323
             324: 283(f64vec) Load 285(vf64)
             325: 283(f64vec) GroupNonUniformFMax 14 InclusiveScan 324
                              Store 285(vf64) 325
             326: 283(f64vec) Load 285(vf64)
             327: 283(f64vec) GroupNonUniformFAdd 14 ExclusiveScan 326
                              Store 285(vf64) 327
             328: 283(f64vec) Load 285(vf64)
             329: 283(f64vec) GroupNonUniformFMul 14 ExclusiveScan 328
                              Store 285(vf64) 329
             330: 283(f64vec) Load 285(vf64)
             331: 283(f64vec) GroupNonUniformFMin 14 ExclusiveScan 330
                              Store 285(vf64) 331
             332: 283(f64vec) Load 285(vf64)
             333: 283(f64vec) GroupNonUniformFMax 14 ExclusiveScan 332
                              Store 285(vf64) 333
             334: 283(f64vec) Load 285(vf64)
             335: 283(f64vec) GroupNonUniformFAdd 14 ClusteredReduce 334 40
                              Store 285(vf64) 335
             336: 283(f64vec) Load 285(vf64)
             337: 283(f64vec) GroupNonUniformFMul 14 ClusteredReduce 336 40
                              Store 285(vf64) 337
             338: 283(f64vec) Load 285(vf64)
             339: 283(f64vec) GroupNonUniformFMin 14 ClusteredReduce 338 40
                              Store 285(vf64) 339
             340: 283(f64vec) Load 285(vf64)
             341: 283(f64vec) GroupNonUniformFMax 14 ClusteredReduce 340 40
                              Store 285(vf64) 341
             342: 283(f64vec) Load 285(vf64)
             343: 283(f64vec) GroupNonUniformQuadBroadcast 14 342 17
                              Store 285(vf64) 343
             344: 283(f64vec) Load 285(vf64)
             345: 283(f64vec) GroupNonUniformQuadSwap 14 344 101
                              Store 285(vf64) 345
             346: 283(f64vec) Load 285(vf64)
             347: 283(f64vec) GroupNonUniformQuadSwap 14 346 17
                              Store 285(vf64) 347
             348: 283(f64vec) Load 285(vf64)
             349: 283(f64vec) GroupNonUniformQuadSwap 14 348 106
                              Store 285(vf64) 349
             350: 283(f64vec) Load 285(vf64)
             351:  108(ivec4) GroupNonUniformPartitionNV 350
                              Store 110(vu4) 351
             352: 283(f64vec) Load 285(vf64)
             353:  108(ivec4) Load 110(vu4)
             354: 283(f64vec) GroupNonUniformFAdd 14 PartitionedReduceNV 352 353
                              Store 285(vf64) 354
             355: 283(f64vec) Load 285(vf64)
             356:  108(ivec4) Load 110(vu4)
             357: 283(f64vec) GroupNonUniformFMul 14 PartitionedReduceNV 355 356
                              Store 285(vf64) 357
             358: 283(f64vec) Load 285(vf64)
             359:  108(ivec4) Load 110(vu4)
             360: 283(f64vec) GroupNonUniformFMin 14 PartitionedReduceNV 358 359
                              Store 285(vf64) 360
             361: 283(f64vec) Load 285(vf64)
             362:  108(ivec4) Load 110(vu4)
             363: 283(f64vec) GroupNonUniformFMax 14 PartitionedReduceNV 361 362
                              Store 285(vf64) 363
             364: 283(f64vec) Load 285(vf64)
             365:  108(ivec4) Load 110(vu4)
             366: 283(f64vec) GroupNonUniformFAdd 14 PartitionedInclusiveScanNV 364 365
                              Store 285(vf64) 366
             367: 283(f64vec) Load 285(vf64)
             368:  108(ivec4) Load 110(vu4)
             369: 283(f64vec) GroupNonUniformFMul 14 PartitionedInclusiveScanNV 367 368
                              Store 285(vf64) 369
             370: 283(f64vec) Load 285(vf64)
             371:  108(ivec4) Load 110(vu4)
             372: 283(f64vec) GroupNonUniformFMin 14 PartitionedInclusiveScanNV 370 371
                              Store 285(vf64) 372
             373: 283(f64vec) Load 285(vf64)
             374:  108(ivec4) Load 110(vu4)
             375: 283(f64vec) GroupNonUniformFMax 14 PartitionedInclusiveScanNV 373 374
                              Store 285(vf64) 375
             376: 283(f64vec) Load 285(vf64)
             377:  108(ivec4) Load 110(vu4)
             378: 283(f64vec) GroupNonUniformFAdd 14 PartitionedExclusiveScanNV 376 377
                              Store 285(vf64) 378
             379: 283(f64vec) Load 285(vf64)
             380:  108(ivec4) Load 110(vu4)
             381: 283(f64vec) GroupNonUniformFMul 14 PartitionedExclusiveScanNV 379 380
                              Store 285(vf64) 381
             382: 283(f64vec) Load 285(vf64)
             383:  108(ivec4) Load 110(vu4)
             384: 283(f64vec) GroupNonUniformFMin 14 PartitionedExclusiveScanNV 382 383
                              Store 285(vf64) 384
             385: 283(f64vec) Load 285(vf64)
             386:  108(ivec4) Load 110(vu4)
             387: 283(f64vec) GroupNonUniformFMax 14 PartitionedExclusiveScanNV 385 386
                              Store 285(vf64) 387
             391:   388(bvec) Load 390(vb)
             392:     6(bool) GroupNonUniformAllEqual 14 391
                              Store 8(b) 392
             393:   388(bvec) Load 390(vb)
             394:   388(bvec) GroupNonUniformBroadcast 14 393 17
                              Store 390(vb) 394
             395:   388(bvec) Load 390(vb)
             396:   388(bvec) GroupNonUniformBroadcastFirst 14 395
                              Store 390(vb) 396
             397:   388(bvec) Load 390(vb)
             398:      9(int) Load 23(u)
             399:   388(bvec) GroupNonUniformShuffle 14 397 398
                              Store 390(vb) 399
             400:   388(bvec) Load 390(vb)
             401:      9(int) Load 23(u)
             402:   388(bvec) GroupNonUniformShuffleXor 14 400 401
                              Store 390(vb) 402
             403:   388(bvec) Load 390(vb)
             404:      9(int) Load 23(u)
             405:   388(bvec) GroupNonUniformShuffleUp 14 403 404
                              Store 390(vb) 405
             406:   388(bvec) Load 390(vb)
             407:      9(int) Load 23(u)
             408:   388(bvec) GroupNonUniformShuffleDown 14 406 407
                              Store 390(vb) 408
             409:   388(bvec) Load 390(vb)
             410:      9(int) Load 23(u)
             411:   388(bvec) GroupNonUniformRotateKHR 14 409 410
                              Store 390(vb) 411
             412:   388(bvec) Load 390(vb)
             413:      9(int) Load 23(u)
             414:   388(bvec) GroupNonUniformRotateKHR 14 412 413 40
                              Store 390(vb) 414
             415:   388(bvec) Load 390(vb)
             416:   388(bvec) GroupNonUniformLogicalAnd 14 Reduce 415
                              Store 390(vb) 416
             417:   388(bvec) Load 390(vb)
             418:   388(bvec) GroupNonUniformLogicalOr 14 Reduce 417
                              Store 390(vb) 418
             419:   388(bvec) Load 390(vb)
             420:   388(bvec) GroupNonUniformLogicalXor 14 Reduce 419
                              Store 390(vb) 420
             421:   388(bvec) Load 390(vb)
             422:   388(bvec) GroupNonUniformLogicalAnd 14 InclusiveScan 421
                              Store 390(vb) 422
             423:   388(bvec) Load 390(vb)
             424:   388(bvec) GroupNonUniformLogicalOr 14 InclusiveScan 423
                              Store 390(vb) 424
             425:   388(bvec) Load 390(vb)
             426:   388(bvec) GroupNonUniformLogicalXor 14 InclusiveScan 425
                              Store 390(vb) 426
             427:   388(bvec) Load 390(vb)
             428:   388(bvec) GroupNonUniformLogicalAnd 14 ExclusiveScan 427
                              Store 390(vb) 428
             429:   388(bvec) Load 390(vb)
             430:   388(bvec) GroupNonUniformLogicalOr 14 ExclusiveScan 429
                              Store 390(vb) 430
             431:   388(bvec) Load 390(vb)
             432:   388(bvec) GroupNonUniformLogicalXor 14 ExclusiveScan 431
                              Store 390(vb) 432
             433:   388(bvec) Load 390(vb)
             434:   388(bvec) GroupNonUniformLogicalAnd 14 ClusteredReduce 433 40
                              Store 390(vb) 434
             435:   388(bvec) Load 390(vb)
             436:   388(bvec) GroupNonUniformLogicalOr 14 ClusteredReduce 435 40
                              Store 390(vb) 436
             437:   388(bvec) Load 390(vb)
             438:   388(bvec) GroupNonUniformLogicalXor 14 ClusteredReduce 437 40
                              Store 390(vb) 438
             439:   388(bvec) Load 390(vb)
             440:   388(bvec) GroupNonUniformQuadBroadcast 14 439 17
                              Store 390(vb) 440
             441:   388(bvec) Load 390(vb)
             442:   388(bvec) GroupNonUniformQuadSwap 14 441 101
                              Store 390(vb) 442
             443:   388(bvec) Load 390(vb)
             444:   388(bvec) GroupNonUniformQuadSwap 14 443 17
                              Store 390(vb) 444
             445:   388(bvec) Load 390(vb)
             446:   388(bvec) GroupNonUniformQuadSwap 14 445 106
                              Store 390(vb) 446
             447:   388(bvec) Load 390(vb)
             448:  108(ivec4) GroupNonUniformPartitionNV 447
                              Store 110(vu4) 448
             449:   388(bvec) Load 390(vb)
             450:  108(ivec4) Load 110(vu4)
             451:   388(bvec) GroupNonUniformLogicalAnd 14 PartitionedReduceNV 449 450
                              Store 390(vb) 451
             452:   388(bvec) Load 390(vb)
             453:  108(ivec4) Load 110(vu4)
             454:   388(bvec) GroupNonUniformLogicalOr 14 PartitionedReduceNV 452 453
                              Store 390(vb) 454
             455:   388(bvec) Load 390(vb)
             456:  108(ivec4) Load 110(vu4)
             457:   388(bvec) GroupNonUniformLogicalXor 14 PartitionedReduceNV 455 456
                              Store 390(vb) 457
             458:   388(bvec) Load 390(vb)
             459:  108(ivec4) Load 110(vu4)
             460:   388(bvec) GroupNonUniformLogicalAnd 14 PartitionedInclusiveScanNV 458 459
                              Store 390(vb) 460
             461:   388(bvec) Load 390(vb)
             462:  108(ivec4) Load 110(vu4)
             463:   388(bvec) GroupNonUniformLogicalOr 14 PartitionedInclusiveScanNV 461 462
                              Store 390(vb) 463
             464:   388(bvec) Load 390(vb)
             465:  108(ivec4) Load 110(vu4)
             466:   388(bvec) GroupNonUniformLogicalXor 14 PartitionedInclusiveScanNV 464 465
                              Store 390(vb) 466
             467:   388(bvec) Load 390(vb)
             468:  108(ivec4) Load 110(vu4)
             469:   388(bvec) GroupNonUniformLogicalAnd 14 PartitionedExclusiveScanNV 467 468
                              Store 390(vb) 469
             470:   388(bvec) Load 390(vb)
             471:  108(ivec4) Load 110(vu4)
             472:   388(bvec) GroupNonUniformLogicalOr 14 PartitionedExclusiveScanNV 470 471
                              Store 390(vb) 472
             473:   388(bvec) Load 390(vb)
             474:  108(ivec4) Load 110(vu4)
             475:   388(bvec) GroupNonUniformLogicalXor 14 PartitionedExclusiveScanNV 473 474
                              Store 390(vb) 475
             480: 477(i64vec) Load 479(vu64)
             481:     6(bool) GroupNonUniformAllEqual 14 480
                              Store 8(b) 481
             482: 477(i64vec) Load 479(vu64)
             483: 477(i64vec) GroupNonUniformBroadcast 14 482 17
                              Store 479(vu64) 483
             484: 477(i64vec) Load 479(vu64)
             485: 477(i64vec) GroupNonUniformBroadcastFirst 14 484
                              Store 479(vu64) 485
             486: 477(i64vec) Load 479(vu64)
             487:      9(int) Load 23(u)
             488: 477(i64vec) GroupNonUniformShuffle 14 486 487
                              Store 479(vu64) 488
             489: 477(i64vec) Load 479(vu64)
             490:      9(int) Load 23(u)
             491: 477(i64vec) GroupNonUniformShuffleXor 14 489 490
                              Store 479(vu64) 491
             492: 477(i64vec) Load 479(vu64)
             493:      9(int) Load 23(u)
             494: 477(i64vec) GroupNonUniformShuffleUp 14 492 493
                              Store 479(vu64) 494
             495: 477(i64vec) Load 479(vu64)
             496:      9(int) Load 23(u)
             497: 477(i64vec) GroupNonUniformShuffleDown 14 495 496
                              Store 479(vu64) 497
             498: 477(i64vec) Load 479(vu64)
             499:      9(int) Load 23(u)
             500: 477(i64vec) GroupNonUniformRotateKHR 14 498 499
                              Store 479(vu64) 500
             501: 477(i64vec) Load 479(vu64)
             502:      9(int) Load 23(u)
             503: 477(i64vec) GroupNonUniformRotateKHR 14 501 502 40
                              Store 479(vu64) 503
             504: 477(i64vec) Load 479(vu64)
             505: 477(i64vec) GroupNonUniformIAdd 14 Reduce 504
                              Store 479(vu64) 505
             506: 477(i64vec) Load 479(vu64)
             507: 477(i64vec) GroupNonUniformIMul 14 Reduce 506
                              Store 479(vu64) 507
             508: 477(i64vec) Load 479(vu64)
             509: 477(i64vec) GroupNonUniformUMin 14 Reduce 508
                              Store 479(vu64) 509
             510: 477(i64vec) Load 479(vu64)
             511: 477(i64vec) GroupNonUniformUMax 14 Reduce 510
                              Store 479(vu64) 511
             512: 477(i64vec) Load 479(vu64)
             513: 477(i64vec) GroupNonUniformBitwiseAnd 14 Reduce 512
                              Store 479(vu64) 513
             514: 477(i64vec) Load 479(vu64)
             515: 477(i64vec) GroupNonUniformBitwiseOr 14 Reduce 514
                              Store 479(vu64) 515
             516: 477(i64vec) Load 479(vu64)
             517: 477(i64vec) GroupNonUniformBitwiseXor 14 Reduce 516
                              Store 479(vu64) 517
             518: 477(i64vec) Load 479(vu64)
             519: 477(i64vec) GroupNonUniformIAdd 14 InclusiveScan 518
                              Store 479(vu64) 519
             520: 477(i64vec) Load 479(vu64)
             521: 477(i64vec) GroupNonUniformIMul 14 InclusiveScan 520
                              Store 479(vu64) 521
             522: 477(i64vec) Load 479(vu64)
             523: 477(i64vec) GroupNonUniformUMin 14 InclusiveScan 522
                              Store 479(vu64) 523
             524: 477(i64vec) Load 479(vu64)
             525: 477(i64vec) GroupNonUniformUMax 14 InclusiveScan 524
                              Store 479(vu64) 525
             526: 477(i64vec) Load 479(vu64)
             527: 477(i64vec) GroupNonUniformBitwiseAnd 14 InclusiveScan 526
                              Store 479(vu64) 527
             528: 477(i64vec) Load 479(vu64)
             529: 477(i64vec) GroupNonUniformBitwiseOr 14 InclusiveScan 528
                              Store 479(vu64) 529
             530: 477(i64vec) Load 479(vu64)
             531: 477(i64vec) GroupNonUniformBitwiseXor 14 InclusiveScan 530
                              Store 479(vu64) 531
             532: 477(i64vec) Load 479(vu64)
             533: 477(i64vec) GroupNonUniformIAdd 14 ExclusiveScan 532
                              Store 479(vu64) 533
             534: 477(i64vec) Load 479(vu64)
             535: 477(i64vec) GroupNonUniformIMul 14 ExclusiveScan 534
                              Store 479(vu64) 535
             536: 477(i64vec) Load 479(vu64)
             537: 477(i64vec) GroupNonUniformUMin 14 ExclusiveScan 536
                              Store 479(vu64) 537
             538: 477(i64vec) Load 479(vu64)
             539: 477(i64vec) GroupNonUniformUMax 14 ExclusiveScan 538
                              Store 479(vu64) 539
             540: 477(i64vec) Load 479(vu64)
             541: 477(i64vec) GroupNonUniformBitwiseAnd 14 ExclusiveScan 540
                              Store 479(vu64) 541
             542: 477(i64vec) Load 479(vu64)
             543: 477(i64vec) GroupNonUniformBitwiseOr 14 ExclusiveScan 542
                              Store 479(vu64) 543
             544: 477(i64vec) Load 479(vu64)
             545: 477(i64vec) GroupNonUniformBitwiseXor 14 ExclusiveScan 544
                              Store 479(vu64) 545
             546: 477(i64vec) Load 479(vu64)
             547: 477(i64vec) GroupNonUniformIAdd 14 ClusteredReduce 546 40
                              Store 479(vu64) 547
             548: 477(i64vec) Load 479(vu64)
             549: 477(i64vec) GroupNonUniformIMul 14 ClusteredReduce 548 40
                              Store 479(vu64) 549
             550: 477(i64vec) Load 479(vu64)
             551: 477(i64vec) GroupNonUniformUMin 14 ClusteredReduce 550 40
                              Store 479(vu64) 551
             552: 477(i64vec) Load 479(vu64)
             553: 477(i64vec) GroupNonUniformUMax 14 ClusteredReduce 552 40
                              Store 479(vu64) 553
             554: 477(i64vec) Load 479(vu64)
             555: 477(i64vec) GroupNonUniformBitwiseAnd 14 ClusteredReduce 554 40
                              Store 479(vu64) 555
             556: 477(i64vec) Load 479(vu64)
             557: 477(i64vec) GroupNonUniformBitwiseOr 14 ClusteredReduce 556 40
                              Store 479(vu64) 557
             558: 477(i64vec) Load 479(vu64)
             559: 477(i64vec) GroupNonUniformBitwiseXor 14 ClusteredReduce 558 40
                              Store 479(vu64) 559
             560: 477(i64vec) Load 479(vu64)
             561: 477(i64vec) GroupNonUniformQuadBroadcast 14 560 17
                              Store 479(vu64) 561
             562: 477(i64vec) Load 479(vu64)
             563: 477(i64vec) GroupNonUniformQuadSwap 14 562 101
                              Store 479(vu64) 563
             564: 477(i64vec) Load 479(vu64)
             565: 477(i64vec) GroupNonUniformQuadSwap 14 564 17
                              Store 479(vu64) 565
             566: 477(i64vec) Load 479(vu64)
             567: 477(i64vec) GroupNonUniformQuadSwap 14 566 106
                              Store 479(vu64) 567
             568: 477(i64vec) Load 479(vu64)
             569:  108(ivec4) GroupNonUniformPartitionNV 568
                              Store 110(vu4) 569
             570: 477(i64vec) Load 479(vu64)
             571:  108(ivec4) Load 110(vu4)
             572: 477(i64vec) GroupNonUniformIAdd 14 PartitionedReduceNV 570 571
                              Store 479(vu64) 572
             573: 477(i64vec) Load 479(vu64)
             574:  108(ivec4) Load 110(vu4)
             575: 477(i64vec) GroupNonUniformIMul 14 PartitionedReduceNV 573 574
                              Store 479(vu64) 575
             576: 477(i64vec) Load 479(vu64)
             577:  108(ivec4) Load 110(vu4)
             578: 477(i64vec) GroupNonUniformUMin 14 PartitionedReduceNV 576 577
                              Store 479(vu64) 578
             579: 477(i64vec) Load 479(vu64)
             580:  108(ivec4) Load 110(vu4)
             581: 477(i64vec) GroupNonUniformUMax 14 PartitionedReduceNV 579 580
                              Store 479(vu64) 581
             582: 477(i64vec) Load 479(vu64)
             583:  108(ivec4) Load 110(vu4)
             584: 477(i64vec) GroupNonUniformBitwiseAnd 14 PartitionedReduceNV 582 583
                              Store 479(vu64) 584
             585: 477(i64vec) Load 479(vu64)
             586:  108(ivec4) Load 110(vu4)
             587: 477(i64vec) GroupNonUniformBitwiseOr 14 PartitionedReduceNV 585 586
                              Store 479(vu64) 587
             588: 477(i64vec) Load 479(vu64)
             589:  108(ivec4) Load 110(vu4)
             590: 477(i64vec) GroupNonUniformBitwiseXor 14 PartitionedReduceNV 588 589
                              Store 479(vu64) 590
             591: 477(i64vec) Load 479(vu64)
             592:  108(ivec4) Load 110(vu4)
             593: 477(i64vec) GroupNonUniformIAdd 14 PartitionedInclusiveScanNV 591 592
                              Store 479(vu64) 593
             594: 477(i64vec) Load 479(vu64)
             595:  108(ivec4) Load 110(vu4)
             596: 477(i64vec) GroupNonUniformIMul 14 PartitionedInclusiveScanNV 594 595
                              Store 479(vu64) 596
             597: 477(i64vec) Load 479(vu64)
             598:  108(ivec4) Load 110(vu4)
             599: 477(i64vec) GroupNonUniformUMin 14 PartitionedInclusiveScanNV 597 598
                              Store 479(vu64) 599
             600: 477(i64vec) Load 479(vu64)
             601:  108(ivec4) Load 110(vu4)
             602: 477(i64vec) GroupNonUniformUMax 14 PartitionedInclusiveScanNV 600 601
                              Store 479(vu64) 602
             603: 477(i64vec) Load 479(vu64)
             604:  108(ivec4) Load 110(vu4)
             605: 477(i64vec) GroupNonUniformBitwiseAnd 14 PartitionedInclusiveScanNV 603 604
                              Store 479(vu64) 605
             606: 477(i64vec) Load 479(vu64)
             607:  108(ivec4) Load 110(vu4)
             608: 477(i64vec) GroupNonUniformBitwiseOr 14 PartitionedInclusiveScanNV 606 607
                              Store 479(vu64) 608
             609: 477(i64vec) Load 479(vu64)
             610:  108(ivec4) Load 110(vu4)
             611: 477(i64vec) GroupNonUniformBitwiseXor 14 PartitionedInclusiveScanNV 609 610
                              Store 479(vu64) 611
             612: 477(i64vec) Load 479(vu64)
             613:  108(ivec4) Load 110(vu4)
             614: 477(i64vec) GroupNonUniformIAdd 14 PartitionedExclusiveScanNV 612 613
                              Store 479(vu64) 614
             615: 477(i64vec) Load 479(vu64)
             616:  108(ivec4) Load 110(vu4)
             617: 477(i64vec) GroupNonUniformIMul 14 PartitionedExclusiveScanNV 615 616
                              Store 479(vu64) 617
             618: 477(i64vec) Load 479(vu64)
             619:  108(ivec4) Load 110(vu4)
             620: 477(i64vec) GroupNonUniformUMin 14 PartitionedExclusiveScanNV 618 619
                              Store 479(vu64) 620
             621: 477(i64vec) Load 479(vu64)
             622:  108(ivec4) Load 110(vu4)
             623: 477(i64vec) GroupNonUniformUMax 14 PartitionedExclusiveScanNV 621 622
                              Store 479(vu64) 623
             624: 477(i64vec) Load 479(vu64)
             625:  108(ivec4) Load 110(vu4)
             626: 477(i64vec) GroupNonUniformBitwiseAnd 14 PartitionedExclusiveScanNV 624 625
                              Store 479(vu64) 626
             627: 477(i64vec) Load 479(vu64)
             628:  108(ivec4) Load 110(vu4)
             629: 477(i64vec) GroupNonUniformBitwiseOr 14 PartitionedExclusiveScanNV 627 628
                              Store 479(vu64) 629
             630: 477(i64vec) Load 479(vu64)
             631:  108(ivec4) Load 110(vu4)
             632: 477(i64vec) GroupNonUniformBitwiseXor 14 PartitionedExclusiveScanNV 630 631
                              Store 479(vu64) 632
                              Return
                              FunctionEnd
